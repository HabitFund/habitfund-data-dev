import pandas as pd
import json
import os
import pycountry
import urllib.parse

# 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì‹œíŠ¸ ID ê°€ì ¸ì˜¤ê¸° (ê³µë°± ì œê±° ë° ë³´ì•ˆ ìœ ì§€)
SHEET_ID = os.environ.get('GOOGLE_SHEET_ID', '').strip()

if not SHEET_ID:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (Secretsê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ë•Œì˜ Fallback)
    SHEET_ID = "1qfWSyzZ0ny2DZVRciA9dr_gYlp6UCierU5o6Mbo9UPU"

# ì•ˆì „í•˜ê²Œ URL ì¸ì½”ë”© ì²˜ë¦¬ (í•œê¸€ ë“± ë°©ì§€)
encoded_id = urllib.parse.quote(SHEET_ID)
SHEET_URL = f"https://docs.google.com/spreadsheets/d/{encoded_id}/export?format=csv"

def get_country_info(name):
    """êµ­ê°€ ì´ë¦„ìœ¼ë¡œ ì½”ë“œ, í’€ë„¤ì„, êµ­ê¸° ì´ë¯¸ì§€ URLì„ ë°˜í™˜"""
    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ë° ë§¤í•‘ ì˜ˆì™¸ ì²˜ë¦¬
    exceptions = {
        "South Korea": ("kr", "South Korea"),
        "United States": ("us", "United States"),
        "Global": ("global", "Global")
    }
    
    if name in exceptions:
        code, full_name = exceptions[name]
    else:
        try:
            # pycountryë¥¼ ì´ìš©í•œ í‘œì¤€ êµ­ê°€ ì •ë³´ íƒìƒ‰
            lookup = pycountry.countries.lookup(name)
            code = lookup.alpha_2.lower()
            full_name = lookup.name
        except:
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì°¾ì§€ ëª»í•  ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
            code = name.lower().replace(" ", "_")
            full_name = name

    # êµ­ê¸° ì´ë¯¸ì§€ ì„œë¹„ìŠ¤ (flagcdn) í™œìš©
    if code == "global":
        flag_url = "https://flagcdn.com/w40/un.png"  # Globalì€ UNê¸°ë¡œ ëŒ€ì²´
    else:
        flag_url = f"https://flagcdn.com/w40/{code}.png"
        
    return code, full_name, flag_url

def clean_category(val):
    """'category - ì„¤ëª…' í˜•ì‹ì—ì„œ keyê°’ë§Œ ì¶”ì¶œ"""
    if not val: return ""
    return str(val).split(' - ')[0].strip()

def index_to_id(file_code, idx):
    """ê³ ìœ  ID ìƒì„± (ì˜ˆ: kr_001)"""
    return f"{file_code}_{idx+1:03d}"

def main():
    # ë°ì´í„° ë¡œë“œ ë° NaN(ê²°ì¸¡ì¹˜) ì²˜ë¦¬
    try:
        df = pd.read_csv(SHEET_URL)
        df = df.fillna("")
    except Exception as e:
        print(f"âŒ Error loading sheet: {e}")
        return

    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs('contributors', exist_ok=True)
    
    # index.jsonì— ë‹´ì„ êµ­ê°€ ë¦¬ìŠ¤íŠ¸
    index_data = []
    
    # 2. êµ­ê°€ë³„ ê·¸ë£¹í™” ë° ê°œë³„ JSON íŒŒì¼ ìƒì„±
    for country_name, group in df.groupby('Country'):
        # êµ­ê°€ ìƒì„¸ ì •ë³´ íšë“
        file_code, full_name, flag_url = get_country_info(country_name)
        
        file_name = f"{file_code}.json"
        relative_path = f"contributors/{file_name}"
        
        json_data = []
        for i, (index, row) in enumerate(group.iterrows()):
            item = {
                "id": index_to_id(file_code, i),
                "name": row['Organization Name'],
                "category": clean_category(row['Category']),
                "country": file_code.upper(),
                "tags": [t.strip() for t in str(row['Search Tags']).split(',')] if row['Search Tags'] else [],
                "url": row['Official URL'],
                "desc": row['Description']
            }
            json_data.append(item)
            
        # ê° êµ­ê°€ë³„ JSON ì €ì¥
        with open(relative_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        # 3. ì¸ë±ìŠ¤ ì •ë³´ ìˆ˜ì§‘ (í’€ë„¤ì„ ë° êµ­ê¸° í¬í•¨)
        index_data.append({
            "country": full_name,      # êµ­ê°€ ì „ì²´ ì´ë¦„
            "code": file_code,      # kr, us ë“± ì†Œë¬¸ì ì½”ë“œ
            "flag": flag_url,       # êµ­ê¸° ì´ë¯¸ì§€ URL
            "path": relative_path,  # íŒŒì¼ ê²½ë¡œ
            "count": len(json_data) # í¬í•¨ëœ ë‹¨ì²´ ìˆ˜
        })
        print(f"âœ… Saved {relative_path} ({len(json_data)} items)")

    # 4. ìµœì¢… index.json íŒŒì¼ ìƒì„±
    index_filename = "contributors/index.json"
    with open(index_filename, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸš€ All Done! Index file created at {index_filename}")

if __name__ == "__main__":
    main()
